# Philosophy of Interpretability Papers

A curated reading list for researchers in the Philosophy of Interpretability.

## Contents

- [Contents](#contents)
- [About](#about)
- [Philosophy of Mechanistic Interpretability](#philosophy-of-mechanistic-interpretability)
- [Philosophy of pre-Mechanistic Interpretability](#philosophy-of-pre-mechanistic-interpretability)
- [Non-Mechanistic Interpretability Paradigms](#non-mechanistic-interpretability-paradigms)
- [Philosophy of Explanations](#philosophy-of-explanations)
- [General Philosophy of Science](#general-philosophy-of-science)
- [Core Interpretability](#core-interpretability)
- [Evaluating Explanations](#evaluating-explanations)
- [Interpreting Representations](#interpreting-representations)
- [Interpreting Computations](#interpreting-computations)
- [Causal Abstractions](#causal-abstractions)
- [Limits of Interpretability](#limits-of-interpretability)
- [Human Studies in Interpretability](#human-studies-in-interpretability)
- [Neuroscience and Cognitive Science](#neuroscience-and-cognitive-science)
- [The Strange Science](#the-strange-science)
- [Other](#other)


## About

Interpretability is the study of producing scientific explanations of
artificial neural networks.
The Philosophy of Interpretability is concerned with understanding the methods and implications of interpretability research and has intersections with epistemology,
Philosophy of Mind, Philosophy of Science, Measurement, Philosophy of Neuroscience,
Cognitive Science and many other disciplines.

---

In this repo, links are organised by topic and have explanations so you can
decide what you would like to read. Especially recommended links are starred ðŸŒŸ

Star this repository to see the latest developments in this research field.

We accept contributions! We strongly encourage researchers & practitioners to
make pull requests with papers, approaches and explanations that they feel
others in the community would benefit from ðŸ¤—

<!-- Ordered by topic, then date published -->

## Philosophy of Mechanistic Interpretability

ðŸŒŸ **Mathematical Philosophy of Explanations in MechInterp, Ayonrinde & Jaburi (2025)**
[pdf](https://arxiv.org/pdf/2505.00808)

> Details a foundation for MechInterp research through an explanatory and information-theoretic lens. Also outlines a technical definition for MechInterp and the limits which follow from this project.

**Propositional Interpretability in Artificial Intelligence, Chalmers (2025)**
[pdf](https://arxiv.org/abs/2501.15740)

> Philosophy of Mind heavyweight David Chalmers lays out a research agenda for interpretability inspired by Psychosemantics and Radical Interpretation. He argues that a goal of interpretability should be to provide a thought log which contains a series of statements which can be understood as Propositional Attitudes - that is attitudes that the AI system holds towards propositional statements expressed in natural language.

<!-- Explaining AI through mechanistic interpretability (Crook) -->

## Philosophy of pre-Mechanistic Interpretability

**The Mythos of Model Interpretability, CMU: Lipton (2016)**
[pdf](https://arxiv.org/abs/1606.03490)

> An early attempt to understand how the opacity problem in deep learning models affects the way that we seek explanations of them and how interpretable AI might function.

<!-- Towards a rigorous science of interpretable machine learning (Kim),
Towards falsifiable interpretability research, -->

## Non-Mechanistic Interpretability Paradigms

<!-- RepEng, Agentic Interp, CoT Interp... -->

## Philosophy of Explanations

<!-- ðŸŒŸ SEP, Craver, ðŸŒŸ Explanation: A mechanist alternative. etc.
What good is an explanation? (Lipton) -->

## General Philosophy of Science

<!-- Kuhn, Popper, ðŸŒŸ Deutsch -->

## Core Interpretability

ðŸŒŸ **Mechanistic Interpretability for AI Safety--A Review, Amsterdam: Bereska & Gavves (2024)**
[pdf](https://arxiv.org/pdf/2404.14082)

> A survey paper of Mechanistic Interpretability techniques and practises. Very well illustrated.

ðŸŒŸ **Zoom In: An Introduction to Circuits, OpenAI: Olah et al (2020)**
[html](https://distill.pub/2020/circuits/zoom-in/)

> Arguably the first paper to outline the core ideas of Mechanistic Interpretability.

<!-- Mathematical Framework of Transformer Circuits -->

<!-- Toy Models of Superposition, Biology of LLMs -->

<!-- Grokking Modular Arithmetic -->

## Evaluating Explanations

<!-- Compact proofs of model performance via mechanistic interpretability, MIB,
Hypothesis testing the circuit hypothesis in LLMs -->

**Explanatory Virtues Framework, Ayonrinde & Jaburi (2025)**
[pdf](https://arxiv.org/pdf/2505.01372)

> An application of Theory Choice to explanations in Mechanistic Interpretability from the Bayesian, Kuhnian, Deutschian, and Nomological lenses.

## Interpreting Representations

ðŸŒŸ **Interpretability as compression: (MDL-SAEs), Ayonrinde et al (2024)**
[pdf](https://arxiv.org/pdf/2410.11179)

> An information-theoretic framework for principled unsupervised feature extraction using Interpreter Models (here SAEs).

ðŸŒŸ **Operationalising Representation in Natural Language Processing, Harding (2023)**
[pdf](https://www.journals.uchicago.edu/doi/abs/10.1086/728685?journalCode=bjps)

> A translation of the core ideas of Representation in the philosophy literature into the NLP/ML framework. Provides the 3 criteria for Representation: Use, Information and Misrepresentation.


<!-- ðŸŒŸ Towards Monosemanticity, Projecting assumptions (Demba) -->

## Interpreting Computations

<!-- APD/ðŸŒŸSPD/SEP? -->

## Causal Abstractions

ðŸŒŸ **Causal abstraction: A theoretical foundation for mechanistic interpretability, Stanford: Geiger et al (2023)**
[pdf](https://arxiv.org/pdf/2301.04709)

> The canonical paper which provides the modern Causal Abstractions foundation for Mechanistic Interpretability.

<!-- Pearl, Causality -->

## Limits of Interpretability

<!-- The computational complexity of circuit discovery for inner interpretability,
An Interpretability Illusion for BERT,
Everything, everywhere, all at once: Is mechanistic interpretability identifiable?
-->

<!-- ## Information Theory and Complexity Theory -->

<!-- ## SLT -->

## Human Studies in Interpretability

**Interpretability is a bidirectional communication problem, UK AISI: Ayonrinde et al (2025)**
[pdf](https://openreview.net/pdf?id=O4LaRH4zSI)

> Analyses the human-interpretation part of interpretability and shows puts forward
> methods for humans to increase their understanding of explanations of model internals.
> A core component of this project is "Concept Enrichment": humans learning new concepts (neologisms)
> by interacting with the internals of AI systems.

<!-- ðŸŒŸ Chess (Schut et al) -->

## Neuroscience and Cognitive Science

<!-- Explanatory models in neuroscience (Cao), Shea, Vision (Marr) -->

**An Inner Interpretability Framework Inspired by Cognitive Neuroscience, Vilas et al (2024)**
[pdf](https://arxiv.org/pdf/2406.01352)

> Details the shared problems in interpretability and cognitive neuroscience
> and lays out a neuroscience-inspired way forwards. A nice bridging of approaches.

## The Strange Science

ðŸŒŸ **Mathematical Philosophy of Explanations in MechInterp, Ayonrinde & Jaburi (2025)**
[pdf](https://arxiv.org/pdf/2505.00808)

> Details a foundation for MechInterp research through an explanatory and information-theoretic lens. Also outlines a technical definition for MechInterp and the limits which follow from this project.

**Explanatory Virtues Framework, Ayonrinde & Jaburi (2025)**
[pdf](https://arxiv.org/pdf/2505.01372)

> An application of Theory Choice to explanations in Mechanistic Interpretability from the Bayesian, Kuhnian, Deutschian, and Nomological lenses.

**Interpretability is a bidirectional communication problem, UK AISI: Ayonrinde et al (2025)**
[pdf](https://openreview.net/pdf?id=O4LaRH4zSI)

> Analyses the human-interpretation part of interpretability and shows puts forward
> methods for humans to increase their understanding of explanations of model internals.
> A core component of this project is "Concept Enrichment": humans learning new concepts (neologisms)
> by interacting with the internals of AI systems.

## Other

**The Urgency of Interpretability, Anthropic: Amodei (2025)**
[html](https://www.darioamodei.com/post/the-urgency-of-interpretability)

> Provides a(n opinionated) history of interpretability and gives a moral case for why interpretability is required from the CEO of one of the frontier AI labs.

<!-- ðŸŒŸ Sparsify (Sharkey), Understanding as compression (Wilkenfeld), MechInterp Needs Phil, ðŸŒŸ MechInterp is not pre-paradigmatic, Natural Kinds, Platonic Representation Hypothesis -->

<br>

---

<br>

Thanks for reading, if you have any suggestions or corrections please submit a
pull request! And please hit the star button to show your appreciation.
