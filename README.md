# Philosophy of Interpretability Papers

A curated reading list for researchers in the Philosophy of Interpretability.

## Contents

- [Contents](#contents)
- [About](#about)
- [Philosophy of Mechanistic Interpretability](#philosophy-of-mechanistic-interpretability)
- [Philosophy of pre-Mechanistic Interpretability](#philosophy-of-pre-mechanistic-interpretability)
- [Core Interpretability](#core-interpretability)
- [Causal Abstractions](#causal-abstractions)
- [Other](#other)


## About

Interpretability is the study of producing scientific explanations of
artificial neural networks.
The Philosophy of Interpretability is concerned with understanding the methods and implications of interpretability research and has intersections with epistemology,
Philosophy of Mind, Philosophy of Science, Measurement, Philosophy of Neuroscience,
Cognitive Science and many other disciplines.

---

In this repo, links are organised by topic and have explanations so you can
decide what you would like to read. Especially recommended links are starred ðŸŒŸ

Star this repository to see the latest developments in this research field.

We accept contributions! We strongly encourage researchers & practitioners to
make pull requests with papers, approaches and explanations that they feel
others in the community would benefit from ðŸ¤—

<!-- Ordered by topic, then date published -->

## Philosophy of Mechanistic Interpretability

ðŸŒŸ **Mathematical Philosophy of Explanations in MechInterp, Ayonrinde & Jaburi (2025)**
[pdf](https://arxiv.org/pdf/2505.00808)

> Details a foundation for MechInterp research through an explanatory and information-theoretic lens. Also outlines a technical definition for MechInterp and the limits which follow from this project.

**Explanatory Virtues Framework, Ayonrinde & Jaburi (2025)**
[pdf](https://arxiv.org/pdf/2505.00808)

> An application of Theory Choice to explanations in Mechanistic Interpretability from the Bayesian, Kuhnian, Deutschian, and Nomological lenses.

**Propositional Interpretability in Artificial Intelligence, Chalmers (2025)**
[pdf](https://arxiv.org/abs/2501.15740)

> Philosophy of Mind heavyweight David Chalmers lays out a research agenda for interpretability inspired by Psychosemantics and Radical Interpretation. He argues that a goal of interpretability should be to provide a thought log which contains a series of statements which can be understood as Propositional Attitudes - that is attitudes that the AI system holds towards propositional statements expressed in natural language.

**Operationalising Representation in Natural Language Processing, Harding (2023)**
[pdf](https://www.journals.uchicago.edu/doi/abs/10.1086/728685?journalCode=bjps)

> A translation of the core ideas of Representation in the philosophy literature into the NLP/ML framework. Provides the 3 criteria for Representation: Use, Information and Misrepresentation.

## Philosophy of pre-Mechanistic Interpretability

**The Mythos of Model Interpretability, CMU: Lipton (2016)**
[pdf](https://arxiv.org/abs/1606.03490)

> An early attempt to understand how the opacity problem in deep learning models affects the way that we seek explanations of them and how interpretable AI might function.

## Core Interpretability

ðŸŒŸ **Mechanistic Interpretability for AI Safety--A Review, Amsterdam: Bereska & Gavves (2024)**
[pdf](https://arxiv.org/pdf/2404.14082)

> A survey paper of Mechanistic Interpretability techniques and practises. Very well illustrated.

ðŸŒŸ **Zoom In: An Introduction to Circuits, OpenAI: Olah et al (2020)**
[html](https://distill.pub/2020/circuits/zoom-in/)

> Arguably the first paper to outline the core ideas of Mechanistic Interpretability.

## Causal Abstractions

ðŸŒŸ **Causal abstraction: A theoretical foundation for mechanistic interpretability, Stanford: Geiger et al (2023)**
[pdf](https://arxiv.org/pdf/2301.04709)

> The canonical paper which provides the modern Causal Abstractions foundation for Mechanistic Interpretability.

<!-- ## Limits of Interpretability -->



<!-- ## Neuroscience and Cognitive Science -->

## Other

**The Urgency of Interpretability, Anthropic: Amodei (2025)**
[html](https://www.darioamodei.com/post/the-urgency-of-interpretability)

> Provides a(n opinionated) history of interpretability and gives a moral case for why interpretability is required from the CEO of one of the frontier AI labs.

<br>

---

<br>

Thanks for reading, if you have any suggestions or corrections please submit a
pull request! And please hit the star button to show your appreciation.
